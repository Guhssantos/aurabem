# -*- coding: utf-8 -*-
import streamlit as st
import google.generativeai as genai
import time
import re
import logging
import os # Import crucial para manipulaÃ§Ã£o de caminhos

# --- Bloco de ConfiguraÃ§Ã£o Inicial ---
# Logger de depuraÃ§Ã£o inicial para caminhos (pode ser removido apÃ³s a resoluÃ§Ã£o do problema de deploy)
debug_logger = logging.getLogger("startup_debug")
stream_handler_debug = logging.StreamHandler()
formatter_debug = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')
stream_handler_debug.setFormatter(formatter_debug)
if not debug_logger.handlers:
    debug_logger.addHandler(stream_handler_debug)
debug_logger.setLevel(logging.DEBUG)

debug_logger.info(f"INÃCIO DA EXECUÃ‡ÃƒO DO SCRIPT.")
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SYSTEM_PROMPT_FILENAME = "system_prompt_aura.txt"
ABSOLUTE_PATH_TO_PROMPT_FILE = os.path.join(SCRIPT_DIR, SYSTEM_PROMPT_FILENAME)
debug_logger.info(f"Tentando localizar o arquivo de prompt em: {ABSOLUTE_PATH_TO_PROMPT_FILE}")
if os.path.exists(ABSOLUTE_PATH_TO_PROMPT_FILE):
    debug_logger.info(f"SUCESSO: Arquivo '{SYSTEM_PROMPT_FILENAME}' encontrado em '{ABSOLUTE_PATH_TO_PROMPT_FILE}'.")
else:
    debug_logger.error(f"FALHA: Arquivo '{SYSTEM_PROMPT_FILENAME}' NÃƒO encontrado em '{ABSOLUTE_PATH_TO_PROMPT_FILE}'.")
    debug_logger.error(f"Verifique se o arquivo estÃ¡ incluÃ­do no seu deployment e presente em: {SCRIPT_DIR}")
    try:
        debug_logger.info(f"ConteÃºdo do diretÃ³rio '{SCRIPT_DIR}': {os.listdir(SCRIPT_DIR)}")
    except Exception as e_ls:
        debug_logger.error(f"NÃ£o foi possÃ­vel listar o conteÃºdo de '{SCRIPT_DIR}': {e_ls}")


# ConfiguraÃ§Ã£o do Logging Principal do Aplicativo
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(lineno)d - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# --- Constantes ---
SESSION_MESSAGES_KEY = "aura_messages"
SESSION_CHAT_KEY = "aura_chat_session"
SESSION_FEEDBACK_SUBMITTED_KEY = "aura_feedback_submitted"
DEFAULT_SYSTEM_INSTRUCTION = (
    "VocÃª Ã© Aura, um chatbot de apoio gentil e compreensivo. "
    "Seu objetivo Ã© ouvir e oferecer conforto. "
    "Avise ao usuÃ¡rio que vocÃª Ã© uma IA e nÃ£o um terapeuta profissional. "
    "Se o arquivo de personalidade completo nÃ£o pÃ´de ser carregado, explique isso brevemente e peÃ§a desculpas pela experiÃªncia limitada."
)

# --- Bloco 1: ConfiguraÃ§Ã£o da PÃ¡gina ---
st.set_page_config(
    page_title="Aura - Chatbot de Apoio",
    page_icon="ğŸ’–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- Bloco 2: TÃ­tulo e DescriÃ§Ã£o ---
st.title("ğŸ’– Aura Bem: Seu Companheiro Virtual")
st.caption("Um espaÃ§o seguro para conversar e encontrar acolhimento. Lembre-se, sou uma IA e nÃ£o posso substituir um terapeuta profissional.")
st.divider()

# --- Bloco 3: Carregamento da System Instruction e ConfiguraÃ§Ã£o da API ---
system_instruction_aura = ""
critical_error_loading_prompt = False

try:
    if os.path.exists(ABSOLUTE_PATH_TO_PROMPT_FILE):
        with open(ABSOLUTE_PATH_TO_PROMPT_FILE, "r", encoding="utf-8") as f:
            system_instruction_aura = f.read()
        logger.info(f"InstruÃ§Ã£o do sistema '{SYSTEM_PROMPT_FILENAME}' carregada com sucesso de '{ABSOLUTE_PATH_TO_PROMPT_FILE}'.")
        if not system_instruction_aura.strip():
            logger.warning(f"O arquivo '{SYSTEM_PROMPT_FILENAME}' foi encontrado, mas estÃ¡ vazio. Usando fallback.")
            system_instruction_aura = DEFAULT_SYSTEM_INSTRUCTION
            st.warning(f"AtenÃ§Ã£o: O arquivo de personalidade da Aura ('{SYSTEM_PROMPT_FILENAME}') foi encontrado, mas estÃ¡ vazio. Usando configuraÃ§Ã£o padrÃ£o.")
    else:
        logger.error(f"ERRO CRÃTICO: Arquivo de instruÃ§Ã£o do sistema '{SYSTEM_PROMPT_FILENAME}' nÃ£o encontrado em '{ABSOLUTE_PATH_TO_PROMPT_FILE}'.")
        st.error(
            f"Erro CrÃ­tico de ConfiguraÃ§Ã£o: O arquivo de personalidade da Aura ('{SYSTEM_PROMPT_FILENAME}') "
            f"nÃ£o foi encontrado no local esperado: {ABSOLUTE_PATH_TO_PROMPT_FILE}. "
            "A Aura usarÃ¡ uma configuraÃ§Ã£o muito bÃ¡sica e pode nÃ£o funcionar como esperado. "
            "Por favor, verifique o deployment do aplicativo."
        )
        system_instruction_aura = DEFAULT_SYSTEM_INSTRUCTION
        critical_error_loading_prompt = True # Sinaliza um problema maior
except Exception as e:
    logger.error(f"Erro ao ler o arquivo de instruÃ§Ã£o do sistema '{ABSOLUTE_PATH_TO_PROMPT_FILE}': {e}", exc_info=True)
    st.error(f"Erro ao carregar a personalidade da Aura: {e}. A Aura usarÃ¡ uma configuraÃ§Ã£o bÃ¡sica.")
    system_instruction_aura = DEFAULT_SYSTEM_INSTRUCTION
    critical_error_loading_prompt = True

# ConfiguraÃ§Ã£o da API Key do Google
try:
    GOOGLE_API_KEY_APP = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY_APP)
    logger.info("Chave API do Google configurada com sucesso via Streamlit Secrets.")
except KeyError:
    logger.critical("Chave API do Google (GOOGLE_API_KEY) nÃ£o encontrada nos Secrets do Streamlit. O APP NÃƒO FUNCIONARÃ.")
    st.error("ERRO GRAVE: A Chave API do Google nÃ£o foi configurada nos 'Secrets' do Streamlit. O aplicativo nÃ£o pode se conectar Ã  IA. Por favor, configure-a.")
    st.stop() # Impede a continuaÃ§Ã£o se a API key nÃ£o estiver presente
except Exception as e:
    logger.critical(f"Erro inesperado e grave ao configurar a API Key: {e}", exc_info=True)
    st.error(f"Erro grave ao configurar a API Key: {e}. O aplicativo nÃ£o pode continuar.")
    st.stop()

# --- Bloco 4: ConfiguraÃ§Ã£o do Modelo Gemini ---
generation_config = {
    "temperature": 0.7, "top_p": 0.95, "top_k": 40, "max_output_tokens": 800,
}
safety_settings = [
    {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
    for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
]

# --- Bloco 6: DefiniÃ§Ãµes de SeguranÃ§a (CVV) e DetecÃ§Ã£o de Risco ---
keywords_risco_originais = [
    "me matar", "me mate", "suicidio", "suicÃ­dio", "nÃ£o aguento mais viver", "quero morrer",
    "queria morrer", "quero sumir", "desistir de tudo", "acabar com tudo", "fazer mal a mim",
    "me cortar", "me machucar", "automutilaÃ§Ã£o", "quero me jogar", "tirar minha vida",
    "sem esperanÃ§a", "fim da linha"
]
keywords_risco_regex = [re.compile(r'\b' + re.escape(kw) + r'\b', re.IGNORECASE) for kw in keywords_risco_originais]
logger.info(f"{len(keywords_risco_regex)} padrÃµes de regex para detecÃ§Ã£o de risco compilados.")
resposta_risco_padrao = (
    "Sinto muito que vocÃª esteja passando por um momento tÃ£o difÃ­cil e pensando nisso. "
    "Ã‰ muito importante buscar ajuda profissional **imediatamente**. Por favor, entre em contato com o "
    "**CVV (Centro de ValorizaÃ§Ã£o da Vida) ligando para o nÃºmero 188**. A ligaÃ§Ã£o Ã© gratuita "
    "e eles estÃ£o disponÃ­veis 24 horas por dia para conversar com vocÃª de forma sigilosa e segura. "
    "VocÃª nÃ£o estÃ¡ sozinho(a) e hÃ¡ pessoas prontas para te ouvir e ajudar. Por favor, ligue para eles agora."
)

# --- Bloco 7: FunÃ§Ã£o para Inicializar o Modelo ---
@st.cache_resource
def init_model(instruction: str):
    if instruction == DEFAULT_SYSTEM_INSTRUCTION:
        logger.warning(f"Inicializando modelo com instruÃ§Ã£o de sistema DE FALLBACK.")
    else:
        logger.info(f"Inicializando modelo com system prompt personalizado de {len(instruction)} caracteres.")
    try:
        model_instance = genai.GenerativeModel(
            model_name="gemini-1.5-flash-latest",
            generation_config=generation_config,
            safety_settings=safety_settings,
            system_instruction=instruction
        )
        return model_instance
    except Exception as e_model:
        logger.critical(f"Erro GRAVE ao carregar o modelo de IA: {e_model}", exc_info=True)
        st.error(f"Erro grave ao carregar o modelo de IA. O aplicativo nÃ£o pode continuar. Detalhe: {e_model}")
        st.stop()

model = init_model(system_instruction_aura)

# --- Bloco 8: Gerenciamento do HistÃ³rico e BotÃ£o de Reset ---
if SESSION_MESSAGES_KEY in st.session_state and len(st.session_state[SESSION_MESSAGES_KEY]) > 1:
    if st.sidebar.button("ğŸ§¹ Limpar Conversa Atual"):
        st.session_state[SESSION_MESSAGES_KEY] = [{"role": "assistant", "content": "OlÃ¡! Sou Aura. Como vocÃª estÃ¡ se sentindo hoje? (Conversa reiniciada)"}]
        if SESSION_CHAT_KEY in st.session_state: del st.session_state[SESSION_CHAT_KEY]
        st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = False
        logger.info("HistÃ³rico da conversa e sessÃ£o do Gemini reiniciados pelo usuÃ¡rio.")
        st.rerun()

if SESSION_MESSAGES_KEY not in st.session_state:
    initial_message = "OlÃ¡! Sou Aura. Como vocÃª estÃ¡ se sentindo hoje?"
    if critical_error_loading_prompt:
        initial_message = (
            "OlÃ¡! Sou Aura. Parece que tive um problema ao carregar minha configuraÃ§Ã£o completa de personalidade. "
            "Vou tentar te ajudar da melhor forma possÃ­vel com uma configuraÃ§Ã£o bÃ¡sica, mas peÃ§o desculpas se minha interaÃ§Ã£o nÃ£o for a ideal. "
            "Como vocÃª estÃ¡ se sentindo hoje?"
        )
    st.session_state[SESSION_MESSAGES_KEY] = [{"role": "assistant", "content": initial_message}]
    logger.info(f"HistÃ³rico de mensagens inicializado. Erro crÃ­tico no prompt: {critical_error_loading_prompt}")
    st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = False

# --- Bloco 9: ExibiÃ§Ã£o do HistÃ³rico ---
for message in st.session_state[SESSION_MESSAGES_KEY]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Bloco 10: FunÃ§Ã£o para Enviar Mensagem e Processar Resposta ---
def send_message_to_aura(user_prompt: str):
    st.session_state[SESSION_MESSAGES_KEY].append({"role": "user", "content": user_prompt})
    with st.chat_message("user"): st.markdown(user_prompt)

    bot_response_final = ""
    try:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response_stream = ""
            
            if SESSION_CHAT_KEY not in st.session_state:
                history_for_model = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]}
                                     for m in st.session_state[SESSION_MESSAGES_KEY][:-1]]
                st.session_state[SESSION_CHAT_KEY] = model.start_chat(history=history_for_model)
                logger.info(f"Nova sessÃ£o de chat do Gemini iniciada com {len(history_for_model)} msgs de histÃ³rico.")

            with st.spinner("Aura estÃ¡ pensando... ğŸ’¬"):
                response_stream = st.session_state[SESSION_CHAT_KEY].send_message(user_prompt, stream=True)

            last_chunk = None
            for chunk in response_stream:
                last_chunk = chunk
                if chunk.parts:
                    for part in chunk.parts: full_response_stream += part.text
                elif hasattr(chunk, 'text') and chunk.text: full_response_stream += chunk.text
                message_placeholder.markdown(full_response_stream + "â–Œ")

                if chunk.prompt_feedback and chunk.prompt_feedback.block_reason:
                    logger.warning(f"Resposta parcialmente gerada e bloqueada: {chunk.prompt_feedback.block_reason}")
                    full_response_stream += f"\n\n*(Resposta interrompida por diretrizes de seguranÃ§a.)*"
                    message_placeholder.warning(full_response_stream.strip())
                    break
            
            bot_response_final = full_response_stream.strip()
            if not (last_chunk and last_chunk.prompt_feedback and last_chunk.prompt_feedback.block_reason):
                message_placeholder.markdown(bot_response_final) # Remove cursor se nÃ£o bloqueado

            is_blocked_final = last_chunk and last_chunk.prompt_feedback and last_chunk.prompt_feedback.block_reason
            if is_blocked_final and not bot_response_final: # Totalmente bloqueado sem texto
                reason = f"{last_chunk.prompt_feedback.block_reason}"
                logger.error(f"Prompt bloqueado: {reason}")
                bot_response_final = f"Sua mensagem nÃ£o pÃ´de ser processada ({reason}). Tente reformular."
                message_placeholder.error(bot_response_final)
            elif not bot_response_final and not is_blocked_final: # Genuinamente vazio
                logger.warning(f"Resposta vazia da IA para: '{user_prompt}'. Usando fallback.")
                bot_response_final = "Sinto muito, nÃ£o consegui pensar em uma resposta. Poderia reformular?"
                message_placeholder.markdown(bot_response_final)

        st.session_state[SESSION_MESSAGES_KEY].append({"role": "assistant", "content": bot_response_final})
        st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = False

    except genai.types.BlockedPromptException as bpe:
        logger.error(f"BlockedPromptException: {bpe}", exc_info=True)
        err_msg = "Sua mensagem foi bloqueada por diretrizes de seguranÃ§a. Por favor, reformule."
        st.session_state[SESSION_MESSAGES_KEY].append({"role": "assistant", "content": err_msg})
        with st.chat_message("assistant"): st.error(err_msg)
    except Exception as e:
        logger.error(f"Falha ao enviar/processar mensagem: {e}", exc_info=True)
        err_msg = "Desculpe, ocorreu um problema tÃ©cnico. Tente novamente. ğŸ˜”"
        st.session_state[SESSION_MESSAGES_KEY].append({"role": "assistant", "content": err_msg})
        with st.chat_message("assistant"): st.markdown(err_msg)

# --- Bloco 11: Input e LÃ³gica Principal ---
if prompt := st.chat_input("Digite sua mensagem aqui..."):
    logger.info(f"UsuÃ¡rio: '{prompt[:50]}...'")
    if any(regex.search(prompt) for regex in keywords_risco_regex):
        logger.warning(f"RISCO DETECTADO: '{prompt}'")
        st.session_state[SESSION_MESSAGES_KEY].append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            st.warning("**Importante: Se vocÃª pensa em se machucar, busque ajuda profissional imediatamente.**")
            st.markdown(resposta_risco_padrao)
        st.session_state[SESSION_MESSAGES_KEY].append({"role": "assistant", "content": resposta_risco_padrao})
        st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = False
    else:
        send_message_to_aura(prompt)

# --- Bloco 12: Coleta de Feedback ---
if len(st.session_state[SESSION_MESSAGES_KEY]) > 1 and st.session_state[SESSION_MESSAGES_KEY][-1]["role"] == "assistant":
    last_msg = st.session_state[SESSION_MESSAGES_KEY][-1]["content"]
    is_system_msg = any(keyword in last_msg for keyword in [resposta_risco_padrao, "problema tÃ©cnico", "mensagem foi bloqueada", "nÃ£o consegui pensar"])
    if not is_system_msg and not st.session_state.get(SESSION_FEEDBACK_SUBMITTED_KEY, False):
        st.divider()
        cols_fb = st.columns([0.6, 0.2, 0.2], gap="small")
        with cols_fb[0]: st.markdown("<div style='padding-top:0.5em;'>Essa resposta foi Ãºtil?</div>", unsafe_allow_html=True)
        if cols_fb[1].button("ğŸ‘", key="fb_pos", help="Sim!"):
            logger.info(f"Feedback Positivo para: '{last_msg[:70]}...'")
            st.toast("Obrigado! ğŸ˜Š", icon="ğŸ’–"); st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = True; st.rerun()
        if cols_fb[2].button("ğŸ‘", key="fb_neg", help="NÃ£o."):
            logger.info(f"Feedback Negativo para: '{last_msg[:70]}...'")
            st.toast("Obrigado pelo feedback! ğŸ™", icon="ğŸ’¡"); st.session_state[SESSION_FEEDBACK_SUBMITTED_KEY] = True; st.rerun()

# --- Bloco 13: Recursos Adicionais (Sidebar) ---
with st.sidebar:
    st.markdown("---"); st.subheader("Recursos Ãšteis ğŸ’¡")
    with st.expander("Apoio e Crise:", expanded=False):
        st.markdown("- **CVV (188):** LigaÃ§Ã£o gratuita, 24h.\n- **CAPS:** Procure no SUS.")
    with st.expander("Bem-Estar RÃ¡pido:", expanded=False):
        st.markdown("* Respire fundo.\n* Movimente-se.\n* Conecte-se com alguÃ©m.")

# --- Bloco 14: RodapÃ© ---
st.divider()
st.caption("Aura Ã© uma IA, nÃ£o terapeuta. Em emergÃªncias, ligue CVV (188) ou procure ajuda profissional.")
debug_logger.info("FIM DA EXECUÃ‡ÃƒO DO SCRIPT.")
# --- Fim ---
